# Limit to 4 prompt combinations per type, minimizing inter-type overlap 
# Randomized: job/machine/operation/duration per sample
# Variable operation count per sample
# No repeated machine within a single job
# Randomly choose evaluation criteria: fastest or best_makespan

import random
import json

path = #"File path of 'llm_on_jssp'/" 

machine_expr = [
    "M{idx}",
    "Machine {idx}",
    "machine number {idx}",
    "the {idx}th machine"
]
job_expr = [
    "Job {idx}",
    "J{idx}",
    "Task {idx}",
    "Operation {idx}"
]
time_expr = [
    "for {dur}",
    "takes {dur} time",
    "for {dur} time units",
    "during {dur} units"
]
op_sep = [
    ", ",
    "; ",
    " then ",
    " and then "
]
job_joiner = [
    "\n",
    " ",
    ". ",
    "; "
]
step_intro = [
    "",
    "First, ",
    "To start, ",
    "Initially, "
]
cont_intro = [
    "next ",
    "after that ",
    "subsequently ",
    "and then ",
    ""
]

criteria_expr = [
    ("fastest", "Choose the solution generated by the solver that completed its computation the fastest among all solvers."),
    ("best_makespan", "Choose the solution generated by the solver that achieved the shortest makespan among all given solvers.")
]

def gen_job_op(machine_pool, min_ops=2, max_ops=5):
    max_ops = min(max_ops, len(machine_pool))
    ops_per_job = random.randint(min_ops, max_ops)
    machines = random.sample(machine_pool, ops_per_job)
    durs = [random.randint(1, 9) for _ in range(ops_per_job)]
    op_strs = []
    for i, (m, d) in enumerate(zip(machines, durs)):
        m_expr = random.choice(machine_expr).format(idx=m+1)
        t_expr = random.choice(time_expr).format(dur=d)
        if i == 0:
            intro = random.choice(step_intro)
        else:
            intro = random.choice(cont_intro)
        op_strs.append(f"{intro}{m_expr} {t_expr}")
    op_sentence = random.choice(op_sep).join(op_strs)
    return op_sentence, machines, durs

def gen_job_line(idx, machine_pool, min_ops=2, max_ops=5):
    job_name = random.choice(job_expr).format(idx=idx+1)
    op_sentence, machines, durs = gen_job_op(machine_pool, min_ops, max_ops)
    if random.random() < 0.3:
        job_line = f"{job_name} has {len(machines)} operations: {op_sentence}"
    elif random.random() < 0.6:
        job_line = f"{job_name}: {op_sentence}"
    else:
        job_line = f"{job_name} consists of {op_sentence}"
    return job_line, machines, durs

def generate_dataset(n_samples=200,
                    min_jobs=2, max_jobs=5,
                    min_machines=3, max_machines=7,
                    min_ops=2, max_ops=5):
    all_samples = []
    for _ in range(n_samples):
        num_jobs = random.randint(min_jobs, max_jobs)
        num_machines = random.randint(min_machines, max_machines)
        machine_pool = list(range(num_machines))
        jobs = []
        matrix = []
        for j in range(num_jobs):
            line, machines, durs = gen_job_line(j, machine_pool, min_ops, max_ops)
            jobs.append(line)
            row = [[m, d] for m, d in zip(machines, durs)]
            matrix.append(row)

        # evaluation label
        criteria, criteria_prompt = random.choice(criteria_expr)

        # instruction, input, output structure
        instruction = (
            "Convert the following job description into a matrix. "
            "Each row is a job. Each tuple is (machine_index, duration). "
            "Also, return the correct label based on the evaluation criterion. "
            "Output must be in JSON format with keys 'matrix' and 'label'."
        )
        input_text = (
            f"Evaluation criterion: {criteria_prompt}\n\n"
            "Job descriptions:\n"
            + "\n".join(jobs)
        )
        output_text = json.dumps({
            "matrix": matrix,
            "label": criteria
        })

        sample = {
            "instruction": instruction,
            "input": input_text,
            "output": output_text
        }
        all_samples.append(sample)
    return all_samples

# inference example
samples = generate_dataset(n_samples=100)

with open(path + "train_llm/dataset_llm1_5k.jsonl", "w", encoding="utf-8") as f:
    for ex in samples:
        f.write(json.dumps(ex) + "\n")

print(f"Sample example:\n{samples[0]}")
print("dataset_llm1_5k.jsonl file created.")


