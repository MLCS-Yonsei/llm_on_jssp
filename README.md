# Job Shop Scheduling from Language: A Heuristic-based Framework with Large Language Models

> Team 5  
> Yujin Kim (2024321236), Yonghwa Seo (2025311450)

---

##  Project Overview

This project presents a novel framework that tackles the **Job Shop Scheduling Problem (JSSP)** using **Large Language Models (LLMs)**. By interpreting human language descriptions and combining them with environment information, the system generates optimized job schedules using a suite of heuristic algorithms.

---

##  Problem Statement

The **Job Shop Scheduling Problem (JSSP)** is a classic optimization task where:

- Multiple jobs must be processed through a set of machines.
- Each job consists of a sequence of operations with defined order.
- Each machine can process only one operation at a time.
- Different jobs may need the same machines, leading to conflicts.

Additionally, this project incorporates **agent movement time** and **collision avoidance** to reflect real-world robotic shop floors.

<br/>

<p align="center">
<img src="https://github.com/user-attachments/assets/f3a91976-0b64-4f2a-a42f-4fe89482c861" width="450" height="300"/>
</p>


---

##  Method

###  LLM-Based Pipeline

This project is structured to accept **natural language job descriptions as input** and produce **natural language responses as output**, enabling seamless interaction between human-readable tasks and scheduling solutions.

<br/>

---
### 1. LLM1 (From Language to Matrix)

LLM1 is designed to convert natural language prompts into structured job matrices. Its input is a natural language job description (prompt), and the output is a JSON object containing both the matrix representation of the job schedule and associated label information (such as the best solver criterion). <br/>
The model was trained on a dataset of 5000 synthetically generated samples, which include randomly varied numbers of jobs and operations, different machine assignments, and diverse processing durations.

- **Input**
```json
{
  "instruction": "Convert the following job description into a matrix. Each row is a job. Each tuple is (machine_index, duration). Also, return the correct label based on the evaluation criterion. Output must be in JSON format with keys 'matrix' and 'label'.",
  "evaluation_criterion": "Choose the solution generated by the solver that achieved the shortest makespan among all given solvers.",
  "job_descriptions": [
    "Job 1: M3 for 2; then M1 for 3; then M4 for 4",
    "Job 2: M2 for 4; then M3 for 2"
  ]
}
```
- **Output**
```json
{
  "matrix": [[[2, 2], [0, 3], [3, 4]],
             [[1, 4], [2, 2]]],
  "label": "best_makespan"
}
```
<br/>

---

### 2. Heuristic Solvers Module
The heuristic solvers module runs a suite of 6 heuristic solvers—including **Tabu Search, Genetic Algorithm (GA), Simulated Annealing (SA), OR-Tools, GRASP, and Ant Colony Optimization (ACO)**—on the matrix-form schedule generated by LLM1. Each solver proposes a solution, and the optimizer evaluates these results based on either the total makespan or the solver’s computation time, depending on the selected criterion.

Additionally, a special design is applied to incorporate movement time between machines. Pseudo-operations representing these movement intervals are added on LLM1's output. The movement time is calculated as the shortest path on a grid map derived from a user-provided environment image (PNG). This grid map assumes that each grid cell takes 1 second to traverse. To prevent conflicts between machines and movement placeholders, each pseudo-operation is assigned a machine index using the rule **"9 + job number + n-th movement"** so that they are distinct and non-overlapping.

- **Input**
```json
{
  "matrix": [[[900, 21], [2, 2], [901, 26], [0, 3], [902, 31], [3, 4]],
             [[910, 34], [1, 4], [911, 25], [2, 2]]],
  "label": "best_makespan"
}
```
- **Output**
```python
{
  "selected_solver": "tabu",
  "solution": {"schedule": [[(900, 0, 21), (2, 21, 23), (901, 23, 49), (0, 49, 52), (902, 52, 83), (3, 83, 87)],
                            [(910, 0, 34), (1, 34, 38), (911, 38, 63), (2, 63, 65)]],
               "makespan": 87}
}
```

<br/>

---

### 3. LLM2 (From Matrix to Language)

LLM2 is responsible for transforming the optimized job schedule, which is represented in matrix format, back into a human-readable natural language explanation. It takes as input the JSON-format schedule matrix generated by the selected solver and produces a textual summary of the job execution plan. This model was trained on a dataset of 1000 samples, each pairing a schedule matrix with a fixed-structure natural language description.

- **Input**
```json
{
  "Convert the following job schedule into natural language:"
  {
  "selected_solver": "tabu",
  "solution": {"schedule": [[[900, 0, 21], [2, 21, 23], [901, 23, 49], [0, 49, 52], [902, 52, 83], [3, 83, 87]],
                            [[910, 0, 34], [1, 34, 38], [911, 38, 63], [2, 63, 65]]],
               "makespan": 87}
  }
  "Answer:"
}
```

- **Output (Final answer with simple parsing)**
```json
"Job 1 is processed on machine 3 from 21 to 23, machine 1 from 49 to 52, machine 4 from 83 to 87."
"Job 2 is processed on machine 2 from 34 to 38, machine 3 from 63 to 65. The total makespan is 87."
```

<br/>

---

###  4. Simulation 
#### Baseline Policy : Lifelong Multi-Agent Pathfinding Policy
#### License
This project is licensed under the MIT License.  
Some portions of the code are adapted from [AIRI-Institute/learn-to-follow](https://github.com/AIRI-Institute/learn-to-follow) under the same license.  
See the [LICENSE](.learn_follow/LICENSE) file for details.

<p align="center">
  <img src="sim/docker/image.png" alt="Lifelong MAPF Example" width="300"/>
</p>

#### Policy Description

The core policy implemented in this project is based on the **Follower** algorithm proposed in  
["Learn to Follow: Decentralized Lifelong Multi-agent Pathfinding via Planning and Learning"](https://arxiv.org/pdf/2310.01207).

**Key features:**
- **Decentralized planning:**  
  Each agent plans its path independently using a global planner, then continually replans based on observed conflicts.
- **Lifelong pathfinding:**  
  Agents are repeatedly assigned new goals in a persistent, dynamic environment, requiring both reactivity and long-term strategy.
- **Local conflict resolution:**  
  A local reinforcement learning (RL) policy resolves collisions and deadlocks online, complementing the global planner.
- **Scalability and robustness:**  
  The combined global planning and local RL allow the system to handle large numbers of agents and complex, cluttered maps.

**Illustration:**  
The figure above visualizes a typical lifelong multi-agent scenario.  
- Each circle represents an agent's goal.  
- The red area shows the local observation used by the RL policy.  
- Agents must coordinate their motion to achieve all goals efficiently, avoiding obstacles and each other in real-time.

For more details, see the original [paper](https://arxiv.org/pdf/2310.01207).

---

**Project Modifications and Scope** 
Job Scheduling with Wait Times:
In this simulation, each agent is given a fixed sequence of targets (jobs) to visit. Upon arriving at each target, the agent waits for a specified processing (wait) time, simulating job execution as in job-shop scheduling (JSSP). This setup allows for realistic modeling of both movement and task processing phases.

**Simulation-Based Evaluation** 
This project does not introduce a new scheduling algorithm. Instead, it evaluates how well predefined job schedules and wait times are executed in a multi-agent environment that uses the decentralized “Follower” policy for pathfinding and conflict resolution.

**Path and Schedule Consistency Analysis** 
The simulation records both the planned job sequences and the actual agent trajectories. By comparing the scheduled plans with the realized execution—including delays, waiting times, and conflicts—it quantifies the effects of path conflicts and congestion on overall task completion.

**Motivation for Path-aware Scheduling** 
Discrepancies between scheduled and actual task completions observed in the simulation motivate further research into scheduling approaches that jointly consider movement, congestion, and task timing. This simulation serves as a baseline for such future work.

#### Summary:
This project provides a simulation framework for analyzing the interplay between job scheduling and multi-agent pathfinding, highlighting the challenges of schedule fidelity in dynamic, congested environments.

---

### Installation:

#### 1. Create and activate the Conda environment (Python 3.8)
conda create -n mlp_jssp_project python=3.8
conda activate mlp_jssp_project

##### 2. Install required Python packages
pip install -r docker/requirements.txt

---

### Map, Goal Sequences, and Wait Sequences

#### Map

- The map configuration file is stored at:  
  `env/test-mapz.yaml`
- You can specify the map file by editing the parser argument in your code:

```python
parser.add_argument('--map_name', type=str, default='mlp_test', help='Map name (default: %(default)s)')
```

#### Goal Sequences & Wait Sequences

- Edit these variables in test.py, specifically in the create_custom_env function:

```python
    goal_sequences = [
        [(0, 13), (0, 7), (0, 18), (10, 12), (0, 24)],
        [(0, 24), (0, 13), (10, 0)],
        [(10, 0), (0, 18), (10, 12)],
        [(0, 7), (10, 24), (0, 24), (0, 18)],
    ]

    wait_sequences = [
        [10, 5, 20, 2, 12],
        [15, 7, 20],
        [10, 15, 20],
        [20, 5, 2, 10],
    ]

    agents_start_pos = [(7, 0), (7, 1), (7, 2), (7, 3)]
```

- goal_sequences: The list of goals (targets) each agent will visit in order.

- wait_sequences: The wait time at each corresponding goal for each agent.

- agents_start_pos: The starting positions for each agent.

---

##  Results 

### 1. LLM Conversion Accuracy

| Model             | EM Acc | Format Fail | Avg Inference Time |
|------------------|--------|-------------|--------------------|
| Fine-tuned LLM   | 36.00% | 32 / 50     | 7.597 s            |
| Mistral-original | 0.00%  | 50 / 50     | 5.066 s            |
| Seq2seq baseline | 0.00%  | 50 / 50     | 0.024 s            |

### 2. Schedule Optimization Example

Job Matrix:
```json
[
  [[2,10],[0,5],[3,20],[5,2],[1,12]],
  [[1,15],[2,7],[6,20]],
  [[6,10],[2,15],[5,20]],
  [[0,20],[4,5],[1,2],[3,10]]
]
```

<p align="center">
  <img src="sim/renders/mlp_test.svg" alt="Lifelong MAPF Example" width="300"/>
</p>

